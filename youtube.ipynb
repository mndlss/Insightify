{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a4484b",
   "metadata": {},
   "source": [
    "# Building a RAG application from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e8eea",
   "metadata": {},
   "source": [
    "Here is a high-level overview of the system we will be building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c01a6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\"\n",
    "yt_link = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\"\n",
    "yt2_link = \"https://youtu.be/Yq0QkCxoTHM?si=3IzccKClJ-sCQnsJ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ad678",
   "metadata": {},
   "source": [
    "# Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e579b",
   "metadata": {},
   "source": [
    "Define the LLM model that we'll use as part of the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96bc8d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759782384.800676 4165676 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1759782384.803935 4165676 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.7\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c6168",
   "metadata": {},
   "source": [
    "### Testing the model by asking a simple question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1c2b3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Los Angeles Lakers last won the NBA championship in **2020**.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e5c8e6f3-50c8-4d64-b4a7-0b98f647fd4c-0', usage_metadata={'input_tokens': 9, 'output_tokens': 16, 'total_tokens': 135})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = model.invoke(\"when did lakers last win NBA?\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c0a92",
   "metadata": {},
   "source": [
    "### Now we will be \"extracting\" this answer by chaining the model with an output parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58e824",
   "metadata": {},
   "source": [
    "Here is what chaining the model with an output parser looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69b20e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Los Angeles Lakers last won the NBA championship in **2020**.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "\n",
    "resp = chain.invoke(\"when did lakers last win NBA?\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becbc4c",
   "metadata": {},
   "source": [
    "# Introducing Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14edd47c",
   "metadata": {},
   "source": [
    "We want to provide the model with some context and the question. \n",
    "Prompt templates are a simple way to define and reuse prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f94b6967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on the context below. If you can\\'t answer the question, reply \"I don\\'t know\". \\nContext\" Palash is in Coreografia, Coreografia is dance club\\nQuestion: What is Coreografia?\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\". \n",
    "Context\" {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context = \"Palash is in Coreografia, Coreografia is dance club\", question = \"What is Coreografia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c525a4",
   "metadata": {},
   "source": [
    "Okay so now that we have this, we can chain the prompt with the model and the output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82f004b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Palash is a member of Coreografia, a dance club in Manipal University Jaipur (MUJ).'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "answer = chain.invoke({\n",
    "    \"context\":\"Palash is a member in Coreografia, Coreografia is a dance club in Manipal University Jaipur (MUJ).\",\n",
    "    \"question\":\"Who Palash?\"\n",
    "    })\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd252483",
   "metadata": {},
   "source": [
    "# Combining Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2bf37",
   "metadata": {},
   "source": [
    "Now we will be combining chains to create a more complex workflow. \n",
    "\n",
    "For example, let's create a second chain that translates the answer from the first chain into a different language\n",
    "\n",
    "For the same, we will first have to start by creating a new prompt template for the translation chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ca2b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\"Translate {answer} to {language}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e15d1",
   "metadata": {},
   "source": [
    "We can now create a new translation chain that combines the result from the first chain with the translation prompt.\n",
    "\n",
    "Here is what the new workflow looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "203c6582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aquí tienes la traducción:\\n\\n**Palash es miembro de Coreografia, un club de baile en Manipal University Jaipur (MUJ).**'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# translation_chain = (\n",
    "#     {\"answer\": chain, \"language\" : itemgetter(\"language\") | translation_prompt | model | parser}    \n",
    "# )\n",
    "\n",
    "# translation_chain = (\n",
    "#     prompt | model | parser | {\"answer\": chain, \"language\" : itemgetter(\"language\")} | translation_prompt | model | parser\n",
    "# )\n",
    "\n",
    "# translation_chain = translation_prompt | model | parser\n",
    "# translation_chain.invoke({\n",
    "#     \"answer\" : answer,\n",
    "#     \"language\" : \"Hindi\"\n",
    "#     })\n",
    "\n",
    "translation_chain = {\"answer\": chain, \"language\" : itemgetter(\"language\")} | translation_prompt | model | parser\n",
    "translation_chain.invoke({\n",
    "    \"context\":\"Palash is a member in Coreografia, Coreografia is a dance club in Manipal University Jaipur (MUJ).\",\n",
    "    \"question\":\"Who is Palash?\",\n",
    "    \"language\":\"Spanish\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0586361",
   "metadata": {},
   "source": [
    "# Transcribing the video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6eae6",
   "metadata": {},
   "source": [
    "As we are working with sourcing a video, we will have to transcribe the video in order to source from it.\n",
    "\n",
    "In order to do that, we will first download the video and then transcribe it.\n",
    "\n",
    "In order to transcribe it, we will first have to convert the video from an mp4 to an mp3 file and then pass that to the llm to generate content.\n",
    "\n",
    "The generated content will then be used as the content for the prompt to the model and questions can be used to ask questions regarding the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf965092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "def transcribe_yt(link):\n",
    "    print(\"Downloading video...\")\n",
    "    yt = YouTube(link)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "\n",
    "    # Downloading audio to a temporary file\n",
    "    temp_path = \"temp_audio.mp3\"\n",
    "    audio_stream.download(filename=temp_path)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    # Now we upload the file to gemini\n",
    "    print(\"Uploading to Gemini...\")\n",
    "    model = genai.GenerativeModel(model=\"gemini-2.5-flash\")\n",
    "    audio_file = genai.upload_file(temp_path)\n",
    "\n",
    "    # Asking gemini to transcribe it\n",
    "    response = model.generate_content([\n",
    "        \"Transcribe this audio file clearly and accurately.\",\n",
    "        audio_file\n",
    "    ])\n",
    "\n",
    "    print(\"Transcription complete.\")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e65bdbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- Step 1: Make sure ffmpeg is visible to this environment ---\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/opt/homebrew/bin\"  # Adjust if ffmpeg is elsewhere\n",
    "\n",
    "# --- Step 2: Configure Gemini ---\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "def transcribe_yt(link):\n",
    "    print(\"🎥 Downloading audio from YouTube...\")\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": \"temp_audio.%(ext)s\",\n",
    "        \"postprocessors\": [{\n",
    "            \"key\": \"FFmpegExtractAudio\",\n",
    "            \"preferredcodec\": \"mp3\",\n",
    "            \"preferredquality\": \"192\",\n",
    "        }],\n",
    "        \"ffmpeg_location\": \"/opt/homebrew/bin\",  # important for macOS ARM users\n",
    "        \"quiet\": True\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([link])\n",
    "\n",
    "    temp_path = \"temp_audio.mp3\"\n",
    "    print(f\"✅ Audio extracted: {temp_path}\")\n",
    "\n",
    "    # --- Step 3: Upload to Gemini ---\n",
    "    print(\"⬆️ Uploading to Gemini...\")\n",
    "    transcribing_model = genai.GenerativeModel(\"gemini-2.5-flash\")  # can change to gemini-1.5-pro if needed\n",
    "    audio_file = genai.upload_file(temp_path)\n",
    "\n",
    "    # --- Step 4: Ask Gemini to transcribe ---\n",
    "    print(\"🧠 Transcribing...\")\n",
    "    response = transcribing_model.generate_content([\n",
    "        \"Transcribe this audio accurately into English text:\",\n",
    "        audio_file\n",
    "    ])\n",
    "\n",
    "    print(\"✅ Transcription complete!\")\n",
    "    return response.text\n",
    "\n",
    "# Example usage:\n",
    "# yt_link = \"https://www.youtube.com/watch?v=XXXX\"\n",
    "# transcription = transcribe_yt(yt_link)\n",
    "# print(transcription[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79c50057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Downloading audio from YouTube...\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759782260.845604 4165676 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1759782260.998372 4165676 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Audio extracted: temp_audio.mp3\n",
      "⬆️ Uploading to Gemini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759782268.249149 4165676 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759782279.748874 4165676 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transcription complete!\n",
      "If you don't have a technical background, but you still want to learn the basics of artificial intelligence, stick around because we're distilling Google's four-hour AI course for beginners into just 10 minutes. I was initially very skeptical because I thought the course would be too conceptual. We're all about practical tips on this channel. And knowing Google, the course might just disappear after one hour. But I found the underlying concepts actually made me better at using tools like Chat GPT and Google Bard, and cleared up a bunch of misconceptions I didn't know I had about AI, machine learning, and large language models.\n",
      "\n",
      "So, starting with the broadest possible question, what is artificial intelligence? It turns out, and I'm so embarrassed to admit I didn't know this. AI is an entire field of study, like physics. And machine learning is a sub-field of AI, much like how thermodynamics is a sub-field of physics. Going down another level, deep learning is a subset of machine learnin\n"
     ]
    }
   ],
   "source": [
    "transcription = transcribe_yt(yt2_link)\n",
    "print(transcription[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2dbc8c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you don\\'t have a technical background, but you still want to learn the basics of artificial intelligence, stick around because we\\'re distilling Google\\'s four-hour AI course for beginners into just 10 minutes. I was initially very skeptical because I thought the course would be too conceptual. We\\'re all about practical tips on this channel. And knowing Google, the course might just disappear after one hour. But I found the underlying concepts actually made me better at using tools like Chat GPT and Google Bard, and cleared up a bunch of misconceptions I didn\\'t know I had about AI, machine learning, and large language models.\\n\\nSo, starting with the broadest possible question, what is artificial intelligence? It turns out, and I\\'m so embarrassed to admit I didn\\'t know this. AI is an entire field of study, like physics. And machine learning is a sub-field of AI, much like how thermodynamics is a sub-field of physics. Going down another level, deep learning is a subset of machine learning, and deep learning models can be further broken down into something called discriminative models and generative models. Large language models, LLMs, also fall under deep learning, and right at the intersection between generative and LLMs, is the technology that powers the applications we\\'re all familiar with, Chat GPT and Google Bard. Let me know in the comments if this was news to you as well.\\n\\nNow that we have an understanding of the overall landscape and you see how the different disciplines sit in relation to each other, let\\'s go over the key takeaways you should know for each level. In a nutshell, machine learning is a program that uses input data to train a model. That trained model can then make predictions based on data it has never seen before. For example, if you train a model based on Nike sales data, you can then use that model to predict how well a new shoe from Adidas would sell based on Adidas sales data.\\n\\nTwo of the most common types of machine learning models are supervised and unsupervised learning models. The key difference between the two is supervised models use labeled data, and unsupervised models use unlabeled data. In this supervised example, we have historical data points that plot the total bill amount at a restaurant against the tip amount. And here the data is labeled. Blue dot equals the order was picked up, and yellow dot equals the order was delivered. Using a supervised learning model, we can now predict how much tip we can expect for the next order, given the bill amount, and whether it\\'s picked up or delivered. For unsupervised learning models, we look at the raw data and see if it naturally falls into groups. In this example, we plotted the employee tenure at a company against their income. We see this group of employees have a relatively high income to years worked ratio versus this group. We can also see all these are unlabeled data. If they were labeled, we would see male, female, years worked, company function, etc. We can now ask this unsupervised learning model to solve a problem like, if a new employee joins, are they on the fast track or not? If they appear on the left, then yes. If they appear on the right, then no.\\n\\nPro tip. Another big difference between the two models is that after a supervised learning model makes a prediction, it will compare that prediction to the training data used to train that model. And if there\\'s a difference, it tries to close that gap. Unsupervised learning models do not do this. By the way, this video is not sponsored, but it is supported by those of you who subscribed to my paid productivity newsletter on Google Tips. Link in the description if you want to learn more.\\n\\nNow we have a basic grasp of machine learning, it\\'s a good time to talk about deep learning, which is just a type of machine learning that uses something called artificial neural networks. Don\\'t worry, all you have to know for now is that artificial neural networks are inspired by the human brain and looks something like this: layers of nodes and neurons. And the more layers there are, the more powerful the model. And because we have these neural networks, we can now do something called semi-supervised learning, whereby a deep learning model is trained on a small amount of labeled data and a large amount of unlabeled data. For example, a bank might use deep learning models to detect fraud. The bank spends a bit of time to tag or label 5% of transactions as either fraudulent or not fraudulent. And they leave the remaining 95% of transactions unlabeled because they don\\'t have the time or resources to label every transaction. The magic happens when the deep learning model uses the 5% of labeled data to learn the basic concepts of the task. Okay, these transactions are good and these are bad. Okay. Apply those learnings to the remaining 95% of unlabeled data, and using this new aggregate data set, the model makes predictions for future transactions. That\\'s pretty cool.\\n\\nAnd we\\'re not done because deep learning can be divided into two types: discriminative and generative models. Discriminative models learn from the relationship between labels of data points and only has the ability to classify those data points. Fraud, not fraud. For example, you have a bunch of pictures, or data points. You purposely label some of them as cats and some of them as dogs. A discriminative model will learn from the label, cat or dog. And if you submit a picture of a dog, it will predict the label for that new data point, a dog.\\n\\nWe finally get to generative AI. Unlike discriminative models, generative models learn about the patterns in the training data. Then after they receive some input, for example, a text prompt from us, they generate something new based on the patterns they just learned. Going back to the animal example, the pictures or data points are not labeled as cat or dog. So a generative model will look for patterns. Oh, these data points all have two ears, four legs, a tail, likes dog food and barks. When asked to generate something called a dog, the generative model generates a completely new image based on the patterns it just learned.\\n\\nThere\\'s a super simple way to determine if something is generative AI or not. If the output is a number, a classification, spam, not spam, or a probability, it is not generative AI. It is Gen AI when the output is natural language text or speech, an image or audio. Basically, generative AI generates new samples that are similar to the data it was trained on. Moving on to different generative AI model types, most of us are familiar with text-to-text models like Chat GPT and Google Bard. Other common model types include text-to-image models like Midjourney, DALL-E, and Stable Diffusion. These can not only generate images, but edit images as well. Text-to-video models, surprise surprise, can generate and edit video footage. Examples include Google\\'s Imagen Video, CogVideo, and the very creatively named Make-A-Video. Text-to-3D models are used to create game assets and a little known example would be OpenAI\\'s Shap-E model. And finally, text-to-task models are trained to perform a specific task. For example, if you type, \"at Gmail, summarize my unread emails,\" Google Bard will look through your inbox and summarize your unread emails.\\n\\nMoving over to large language models. Don\\'t forget that LLMs are also a subset of deep learning, and although there is some overlap, LLMs and Gen AI are not the same thing. An important distinction is that large language models are generally pre-trained with a very large set of data, and then fine-tuned for specific purposes. What does that mean? Imagine you have a pet dog. It can be pre-trained with basic commands like sit, come, down, and stay. It\\'s a good boy and a generalist. But if that same good boy goes on to become a police dog, a guide dog, or a hunting dog, they need to receive specific training so they\\'re fine-tuned for that specialist role. A similar idea applies to large language models. They\\'re first pre-trained to solve common language problems like text classification, question answering, document summarization, and text generation. Then, using smaller industry-specific data sets, these LLMs are fine-tuned to solve specific problems in retail, finance, healthcare, entertainment, and other fields. In the real world, this might mean a hospital uses a pre-trained large language model from one of the big tech companies and fine-tunes that model with its own first-party medical data to improve diagnostic accuracy from X-rays and other medical tests. This is a win-win scenario because large companies can spend billions developing general-purpose large language models, then sell those LLMs to smaller institutions like retail companies, banks, hospitals, who don\\'t have the resources to develop their own large language models, but they have the domain-specific datasets to fine-tune those models.\\n\\nPro tip. If you do end up taking the full course, I\\'ll link it down below, it\\'s completely free. When you\\'re taking notes, you can right-click on the video player and copy video URL at the current time so you can quickly navigate back to that specific part of the video. There are five modules total and you get a badge after completing each module. The content overall is a bit more on the theoretical side, so you definitely want to check out this video on how to master prompting next. See you in the next video in the meantime. Have a great one.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76f12410",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Use the provided video transcript to answer the question.\\n\\n\"\n",
    "    \"Transcript:\\n{context}\\n\\n\"\n",
    "    \"Question: {question}\\n\\n\"\n",
    "    \"Answer clearly and concisely:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8df62534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The video is about distilling Google's four-hour AI course for beginners into a 10-minute summary, covering the basics of artificial intelligence, machine learning, deep learning, generative AI, and large language models.\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribing_chain = prompt | model | parser\n",
    "transcribing_chain.invoke({\n",
    "    \"context\":transcription,\n",
    "    \"question\":\"What is the video about?\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
